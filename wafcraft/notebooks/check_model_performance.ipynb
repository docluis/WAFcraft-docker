{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from src.utils import load_data_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def check_performance(workspace, adv, testing):\n",
    "    workspace_fullpath = f\"/app/wafcraft/data/prepared/{workspace}\"\n",
    "    model_dir = \"model_adv\" if adv else \"model\"\n",
    "    model = joblib.load(f\"{workspace_fullpath}/{model_dir}/{model_dir}.joblib\")\n",
    "    threshold = float(\n",
    "        open(f'{workspace_fullpath}/{model_dir}/threshold{\"_adv\" if adv else \"\"}.txt', \"r\").read()\n",
    "    )\n",
    "    # print(f\"Threshold: {threshold}\")\n",
    "    # print(f\"Model: {model}\")\n",
    "\n",
    "    my_test = load_data_label_vector(f\"{workspace_fullpath}/test.csv\")\n",
    "    other_test = load_data_label_vector(f\"/app/wafcraft/data/prepared/2024-04-07_18-15-53_brown-lot/test.csv\")\n",
    "    my_test_adv = load_data_label_vector(f\"{workspace_fullpath}/test_adv.csv\")\n",
    "\n",
    "    # drop columns that are not vector or label\n",
    "    my_test = my_test[[\"vector\", \"label\"]]\n",
    "    other_test = other_test[[\"vector\", \"label\"]]\n",
    "    my_test_adv = my_test_adv[[\"vector\", \"label\"]]\n",
    "    \n",
    "    if testing == \"my_all\":\n",
    "        test = pd.concat([my_test, my_test_adv])\n",
    "    elif testing == \"my_test\":\n",
    "        test = my_test\n",
    "    elif testing == \"my_test-adv\":\n",
    "        my_test_benign = my_test[my_test[\"label\"] == 0]\n",
    "        test = pd.concat([my_test_adv, my_test_benign])\n",
    "        # test = my_test_adv\n",
    "    elif testing == \"other_test\":\n",
    "        test = other_test\n",
    "    else:\n",
    "        raise ValueError(\"Invalid testing option\")\n",
    "    \n",
    "    print(f\"Testing: {testing}\")\n",
    "    print(f\"Test shape: {test.shape}\")\n",
    "    \n",
    "    X_test, y_test = list(test[\"vector\"]), test[\"label\"]\n",
    "    probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    adjusted_predictions = (probabilities >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_test, adjusted_predictions)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1981   19]\n",
      " [  79 1921]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1980   20]\n",
      " [  69 1931]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1981   19]\n",
      " [  77 1923]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1971   29]\n",
      " [  45 1955]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1984   16]\n",
      " [  82 1918]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1985   15]\n",
      " [  92 1908]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1984   16]\n",
      " [  88 1912]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1977   23]\n",
      " [  74 1926]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1980   20]\n",
      " [  91 1909]]\n",
      "Testing: other_test\n",
      "Test shape: (4000, 2)\n",
      "CM: [[1972   28]\n",
      " [  45 1955]]\n",
      "Average FPR: 0.010249999999999999\n",
      "Average TPR: 0.9629000000000001\n"
     ]
    }
   ],
   "source": [
    "workspaces = [\n",
    "    \"2024-04-18_14-12-51_lightblue-around\",\n",
    "    \"2024-05-10_15-03-09_darkred-number\",\n",
    "    \"2024-04-22_11-20-36_yellow-majority\",\n",
    "    \"2024-05-10_23-07-35_beige-western\",\n",
    "    \"2024-04-23_05-02-11_cadetblue-right\",\n",
    "    \"2024-04-08_21-57-36_greenyellow-fear\",\n",
    "    \"2024-05-11_07-05-20_honeydew-check\",\n",
    "    \"2024-04-23_02-58-14_blanchedalmond-table\",\n",
    "    \"2024-04-22_18-57-13_darkslateblue-air\",\n",
    "    \"2024-05-11_14-57-56_darkgray-general\",\n",
    "]\n",
    "\n",
    "testing = \"other_test\"\n",
    "\n",
    "all_fprs = []\n",
    "all_tprs = []\n",
    "\n",
    "for workspace in workspaces:\n",
    "    cm = check_performance(workspace, adv=True, testing=testing)\n",
    "    print(f\"CM: {cm}\")\n",
    "    fpr = cm[0][1] / (cm[0][1] + cm[0][0])\n",
    "    tpr = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "    all_fprs.append(fpr)\n",
    "    all_tprs.append(tpr)\n",
    "\n",
    "print(f\"Average FPR: {sum(all_fprs) / len(all_fprs)}\")\n",
    "print(f\"Average TPR: {sum(all_tprs) / len(all_tprs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
