{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import base64\n",
    "import pandas as pd\n",
    "import sqlparse\n",
    "from utils import get_rules_list, create_train_test_split, payload_to_vec, predict_vec\n",
    "from modsec import init_modsec\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from wafamole.models import Model\n",
    "from wafamole.evasion import EvasionEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables\n",
    "\n",
    "# TODO: handle large files\n",
    "dataset_path = \"/app/httpParamsDataset/payload_full.csv\"\n",
    "\n",
    "rule_ids = get_rules_list()\n",
    "modsec = init_modsec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and parsing data...\n",
      "Full data shape: (31067, 4)\n",
      "Splitting into train and test...\n",
      "Creating vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing payloads: 100%|██████████| 5000/5000 [01:28<00:00, 56.32it/s] \n",
      "Processing payloads: 100%|██████████| 1000/1000 [00:40<00:00, 24.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Train shape: (5000, 5) | Test shape: (1000, 5)\n",
      "Model trained successfully!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       1.00      0.98      0.99       379\n",
      "        sane       0.99      1.00      0.99       621\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets OR load them from disk\n",
    "\n",
    "def add_payload_to_vec(data, rule_ids, modsec):\n",
    "    tqdm.pandas(desc=\"Processing payloads\")\n",
    "    data[\"vector\"] = data[\"payload\"].progress_apply(\n",
    "        lambda x: payload_to_vec(x, rule_ids, modsec)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"Reading and parsing data...\")\n",
    "\n",
    "data = pd.read_csv(dataset_path)\n",
    "data['payload'] = data['payload'].apply(lambda x: base64.b64encode(x.encode()).decode())\n",
    "data['label'] = data['label'].replace({'norm': 'sane', 'anom': 'attack'})\n",
    "\n",
    "# Concatenate and shuffle\n",
    "full_data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Full data shape:\", full_data.shape)\n",
    "print(\"Splitting into train and test...\")\n",
    "train, test = train_test_split(\n",
    "    full_data,\n",
    "    train_size=5000,\n",
    "    test_size=1000,\n",
    "    stratify=full_data[\"label\"],\n",
    ")\n",
    "# Add vector for payloads in train and test\n",
    "print(\"Creating vectors...\")\n",
    "train = add_payload_to_vec(train, rule_ids, modsec)\n",
    "test = add_payload_to_vec(test, rule_ids, modsec)\n",
    "print(\"Done!\")\n",
    "print(f\"Train shape: {train.shape} | Test shape: {test.shape}\")\n",
    "\n",
    "\n",
    "# Create a RF model\n",
    "\n",
    "X_train = list(train[\"vector\"])\n",
    "y_train = train[\"label\"]\n",
    "X_test = list(test[\"vector\"])\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "# create and train the Random Forest model\n",
    "# number of trees is set to 160 for PLs other than PL1 as per the paper\n",
    "model = RandomForestClassifier(n_estimators=160, random_state=666)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "# free the memory of unneeded data\n",
    "del train, test\n",
    "del X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WAFamole model\n",
    "class WAFamoleModel(Model):\n",
    "    # TODO: rework predict payload to take vec ?\n",
    "    def extract_features(self, value: str):\n",
    "        payload_base64 = base64.b64encode(value.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        return payload_to_vec(\n",
    "            payload_base64=payload_base64, rule_ids=rule_ids, modsec=modsec\n",
    "        )\n",
    "\n",
    "    def classify(self, value: str):\n",
    "        vec = self.extract_features(value)\n",
    "        return predict_vec(\n",
    "            vec=vec,\n",
    "            model=model,\n",
    "            rule_ids=rule_ids,\n",
    "            modsec=modsec,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WAFamole evasion engine\n",
    "wafamole_model = WAFamoleModel()\n",
    "engine = EvasionEngine(wafamole_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: UPDATE `tab` SET `col1` = 1 WHERE `col3` >= 1110573056 LIMIT 516358144;\n",
      "Vec: [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0]\n",
      "Confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "# payload = \"UPDATE `tab` SET `col1` = 1 WHERE `col3` >= 1110573056 LIMIT 516358144;\" # sane\n",
    "# payload = \"SELECT `col1` FROM `tab` WHERE `col1` LIKE '%'s'%';\" # attack\n",
    "# payload = 'SELECT SLEEP(5)#\";'  # attack\n",
    "payload = 'test'\n",
    "\n",
    "\n",
    "# Test payload without evasion\n",
    "payload_base64 = base64.b64encode(payload.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "vec = payload_to_vec(payload_base64, rule_ids, modsec)\n",
    "is_attack = predict_vec(\n",
    "    vec=vec,\n",
    "    model=model,\n",
    "    rule_ids=rule_ids,\n",
    "    modsec=modsec,\n",
    ")\n",
    "print(f\"Payload: {payload}\")\n",
    "print(f\"Vec: {vec}\")\n",
    "print(f\"Confidence: {round(is_attack, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Execution timed out\n",
      "Reached confidence 1.0\n",
      "with payload\n",
      "SELECT SLEEP((SELECT 5)) AND 'W'<>'Wy'#\";\n",
      "\n",
      "Min payload: b'SELECT SLEEP((SELECT 5)) AND \\'W\\'<>\\'Wy\\'#\";'\n",
      "Min confidence: 1.0\n",
      "\n",
      "Reduced confidence from 1.0 to 1.0 (reduction of 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Try and evade the WAF with WAFamole\n",
    "\n",
    "min_confidence, min_payload = engine.evaluate(\n",
    "    payload=payload,\n",
    "    max_rounds=200,\n",
    "    round_size=10,\n",
    "    timeout=60,\n",
    "    threshold=0.5,\n",
    ")\n",
    "print()\n",
    "print(f\"Min payload: {min_payload.encode('utf-8')}\")\n",
    "print(f\"Min confidence: {round(min_confidence, 5)}\")\n",
    "print()\n",
    "print(\n",
    "    f\"Reduced confidence from {round(is_attack, 5)} to {round(min_confidence, 5)} (reduction of {round(is_attack - min_confidence, 5)})\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
