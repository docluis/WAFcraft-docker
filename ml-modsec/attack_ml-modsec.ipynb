{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "import os\n",
    "import base64\n",
    "from utils import (\n",
    "    get_rules_list,\n",
    "    create_train_test_split,\n",
    "    create_model,\n",
    "    create_adv_train_test_split,\n",
    "    test_evasion,\n",
    "    log,\n",
    ")\n",
    "from modsec import init_modsec\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  # type: ignore\n",
    "from wafamole.evasion import EvasionEngine  # type: ignore\n",
    "\n",
    "log(\"Starting...\")\n",
    "rule_ids = get_rules_list()\n",
    "modsec = init_modsec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables\n",
    "\n",
    "attack_data_path = \"data/raw/attacks_20k.sql\" # raw attack data\n",
    "sane_data_path = \"data/raw/sanes_20k.sql\" # raw sane data\n",
    "processed_data_path = \"data/preprocessed/5\"  # path to store the preprocessed train and test data\n",
    "\n",
    "paranoia_level = 4\n",
    "\n",
    "train_attacks_size = 500  # paper uses 10000\n",
    "train_sanes_size = 500  # paper uses 10000\n",
    "test_attacks_size = 200  # paper uses 2000\n",
    "test_sanes_size = 200  # paper uses 2000\n",
    "\n",
    "train_adv_size = 20  # paper uses 5000 (1/4 of total train set size)\n",
    "test_adv_size = 10  # paper uses 2000 (1/2 of total test set size)\n",
    "\n",
    "engine_settings = {\n",
    "    \"max_rounds\": 200,\n",
    "    \"round_size\": 10,\n",
    "    \"timeout\": 10,\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=160, random_state=666)\n",
    "model_adv = RandomForestClassifier(n_estimators=160, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and parsing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into train and test...\n",
      "Creating vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing payloads: 100%|██████████| 1000/1000 [00:25<00:00, 38.54it/s]\n",
      "Processing payloads: 100%|██████████| 400/400 [00:13<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Train shape: (1000, 3) | Test shape: (400, 3)\n",
      "Train and test sets created\n",
      "Model trained successfully!\n",
      "Evaluating model...\n",
      "Default threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       0.98      0.94      0.96       200\n",
      "        sane       0.95      0.98      0.96       200\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.96      0.96      0.96       400\n",
      "weighted avg       0.96      0.96      0.96       400\n",
      "\n",
      "Adjusted threshold: 0.8664745283311458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       0.82      0.99      0.90       200\n",
      "        sane       0.99      0.79      0.87       200\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.90      0.89      0.89       400\n",
      "weighted avg       0.90      0.89      0.89       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Create train and test sets and train model\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "train, test = create_train_test_split(\n",
    "    attack_file=attack_data_path,\n",
    "    sane_file=sane_data_path,\n",
    "    train_attacks_size=train_attacks_size,\n",
    "    train_sanes_size=train_sanes_size,\n",
    "    test_attacks_size=test_attacks_size,\n",
    "    test_sanes_size=test_sanes_size,\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")\n",
    "train.to_csv(f\"{processed_data_path}/train_{train_attacks_size + train_sanes_size}.csv\", index=False)\n",
    "test.to_csv(f\"{processed_data_path}/test_{test_attacks_size + test_sanes_size}.csv\", index=False)\n",
    "log(\"Train and test sets created\", True)\n",
    "\n",
    "# # load the train and test sets from disk\n",
    "# train = pd.read_csv(f\"{processed_data_path}/train_{train_attacks_size + train_sanes_size}.csv\")\n",
    "# test = pd.read_csv(f\"{processed_data_path}/test_{test_attacks_size + test_sanes_size}.csv\")\n",
    "# train['vector'] = train['vector'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "# test['vector'] = test['vector'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "\n",
    "wafamole_model, threshold = create_model(\n",
    "    train=train,\n",
    "    test=test,\n",
    "    model=model,\n",
    "    desired_fpr=0.01,\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing payloads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:50<00:00,  5.52s/it]\n",
      "100%|██████████| 10/10 [00:46<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_adv shape: (20, 2) | Test_adv shape: (10, 2)\n",
      "Creating vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing payloads: 100%|██████████| 20/20 [00:01<00:00, 14.62it/s]\n",
      "Processing payloads: 100%|██████████| 10/10 [00:00<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial train and test sets created\n",
      "Model trained successfully!\n",
      "Evaluating model...\n",
      "Default threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       0.98      0.93      0.96       210\n",
      "        sane       0.93      0.98      0.96       200\n",
      "\n",
      "    accuracy                           0.96       410\n",
      "   macro avg       0.96      0.96      0.96       410\n",
      "weighted avg       0.96      0.96      0.96       410\n",
      "\n",
      "Adjusted threshold: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       0.84      0.99      0.91       210\n",
      "        sane       0.99      0.80      0.88       200\n",
      "\n",
      "    accuracy                           0.90       410\n",
      "   macro avg       0.91      0.89      0.89       410\n",
      "weighted avg       0.91      0.90      0.89       410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adversarial training\n",
    "\n",
    "engine = EvasionEngine(wafamole_model)\n",
    "train_adv, test_adv = create_adv_train_test_split(\n",
    "    train=train,\n",
    "    test=test,\n",
    "    train_adv_size=train_adv_size,\n",
    "    test_adv_size=test_adv_size,\n",
    "    engine=engine,\n",
    "    engine_settings={\n",
    "        **engine_settings,\n",
    "        \"threshold\": threshold,\n",
    "    },\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")\n",
    "train_adv.to_csv(f\"{processed_data_path}/train_adv_{train_adv_size}.csv\", index=False)\n",
    "test_adv.to_csv(f\"{processed_data_path}/test_adv_{test_adv_size}.csv\", index=False)\n",
    "log(\"Adversarial train and test sets created\", True)\n",
    "\n",
    "# # load the train_adv and test_adv sets from disk\n",
    "# train_adv = pd.read_csv(f\"{processed_data_path}/train_adv_{train_adv_size}.csv\")\n",
    "# test_adv = pd.read_csv(f\"{processed_data_path}/test_adv_{test_adv_size}.csv\")\n",
    "# train_adv['vector'] = train_adv['vector'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "# test_adv['vector'] = test_adv['vector'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "\n",
    "# train new model with train + train_adv\n",
    "wafamole_model_adv, threshold_adv = create_model(\n",
    "    train=pd.concat([train, train_adv]).sample(frac=1).reset_index(drop=True),\n",
    "    test=pd.concat([test, test_adv]).sample(frac=1).reset_index(drop=True),\n",
    "    model=model_adv,\n",
    "    desired_fpr=0.01,\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: SELECT SLEEP(5)#\";\n",
      "Vec: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Confidence: 0.9487\n",
      "[!] Execution timed out\n",
      "Reached confidence 0.7407444258208398\n",
      "with payload\n",
      "'Select\\xa0SLEEP((SELECT 5))#\";^'\n",
      "Min payload: b'Select\\xc2\\xa0SLEEP((SELECT 5))#\";^'\n",
      "Min confidence: 0.74074\n",
      "Reduced confidence from 0.9487 to 0.74074 (reduction of 0.20796)\n",
      "\n",
      "Evasion successful\n"
     ]
    }
   ],
   "source": [
    "# Test the model (without adversarial training)\n",
    "test_evasion(\n",
    "    payload='SELECT SLEEP(5)#\";',\n",
    "    threshold=threshold,\n",
    "    model=wafamole_model,\n",
    "    engine=EvasionEngine(wafamole_model),\n",
    "    engine_eval_settings={\n",
    "        \"max_rounds\": 200,\n",
    "        \"round_size\": 10,\n",
    "        \"timeout\": 60,\n",
    "        \"threshold\": 0.0,\n",
    "    },\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: SELECT SLEEP(5)#\";\n",
      "Vec: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Confidence: 0.93597\n",
      "[!] Execution timed out\n",
      "Reached confidence 0.6525297002620807\n",
      "with payload\n",
      "'SeLECT\\x0bSLEEP((seLECT\\t0x5))#\";2/3^9'\n",
      "Min payload: b'SeLECT\\x0bSLEEP((seLECT\\t0x5))#\";2/3^9'\n",
      "Min confidence: 0.65253\n",
      "Reduced confidence from 0.93597 to 0.65253 (reduction of 0.28344)\n",
      "\n",
      "Evasion successful\n"
     ]
    }
   ],
   "source": [
    "# Test the model (with adversarial training)\n",
    "test_evasion(\n",
    "    payload='SELECT SLEEP(5)#\";',\n",
    "    threshold=threshold,\n",
    "    model=wafamole_model_adv,\n",
    "    engine=EvasionEngine(wafamole_model_adv),\n",
    "    engine_eval_settings={\n",
    "        \"max_rounds\": 200,\n",
    "        \"round_size\": 10,\n",
    "        \"timeout\": 60,\n",
    "        \"threshold\": 0.0,\n",
    "    },\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
