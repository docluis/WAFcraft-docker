{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import (\n",
    "    get_rules_list,\n",
    "    create_train_test_split,\n",
    "    create_model,\n",
    "    create_adv_train_test_split,\n",
    "    test_evasion,\n",
    "    log,\n",
    ")\n",
    "from modsec import init_modsec\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from wafamole.evasion import EvasionEngine  # type: ignore\n",
    "\n",
    "log(\"Starting...\")\n",
    "rule_ids = get_rules_list()\n",
    "modsec = init_modsec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables\n",
    "\n",
    "use_data_from_disk = True\n",
    "\n",
    "attack_data_path = \"data/raw/attacks_20k.sql\" # raw attack data\n",
    "sane_data_path = \"data/raw/sanes_20k.sql\" # raw sane data\n",
    "processed_data_path = \"data/preprocessed/5\"  # path to store the preprocessed train and test data\n",
    "\n",
    "paranoia_level = 5\n",
    "\n",
    "train_attacks_size = 1000  # paper uses 10000\n",
    "train_sanes_size = 1000  # paper uses 10000\n",
    "test_attacks_size = 400  # paper uses 2000\n",
    "test_sanes_size = 400  # paper uses 2000\n",
    "\n",
    "train_adv_size = 20  # paper uses 5000 (1/4 of total train set size)\n",
    "test_adv_size = 10  # paper uses 2000 (1/2 of total test set size)\n",
    "\n",
    "engine_settings = {\n",
    "    \"max_rounds\": 200,\n",
    "    \"round_size\": 10,\n",
    "    \"timeout\": 10,\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=160, random_state=666)\n",
    "model_adv = RandomForestClassifier(n_estimators=160, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "\n",
    "if (not use_data_from_disk) :\n",
    "    if not os.path.exists(processed_data_path):\n",
    "        os.makedirs(processed_data_path)\n",
    "    train, test = create_train_test_split(\n",
    "        attack_file=attack_data_path,\n",
    "        sane_file=sane_data_path,\n",
    "        train_attacks_size=train_attacks_size,\n",
    "        train_sanes_size=train_sanes_size,\n",
    "        test_attacks_size=test_attacks_size,\n",
    "        test_sanes_size=test_sanes_size,\n",
    "        modsec=modsec,\n",
    "        rule_ids=rule_ids,\n",
    "        paranoia_level=paranoia_level,\n",
    "    )\n",
    "    train.to_csv(f\"{processed_data_path}/train_{train_attacks_size + train_sanes_size}.csv\", index=False)\n",
    "    test.to_csv(f\"{processed_data_path}/test_{test_attacks_size + test_sanes_size}.csv\", index=False)\n",
    "    log(\"Train and test sets created\", True)\n",
    "else :\n",
    "    # load the train and test sets from disk\n",
    "    train = pd.read_csv(f\"{processed_data_path}/train_{train_attacks_size + train_sanes_size}.csv\")\n",
    "    test = pd.read_csv(f\"{processed_data_path}/test_{test_attacks_size + test_sanes_size}.csv\")\n",
    "    train['vector'] = train['vector'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
    "    test['vector'] = test['vector'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "wafamole_model, threshold = create_model(\n",
    "    train=train,\n",
    "    test=test,\n",
    "    model=model,\n",
    "    desired_fpr=0.01,\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial training\n",
    "if not use_data_from_disk:\n",
    "    engine = EvasionEngine(wafamole_model)\n",
    "    train_adv, test_adv = create_adv_train_test_split(\n",
    "        train=train,\n",
    "        test=test,\n",
    "        train_adv_size=train_adv_size,\n",
    "        test_adv_size=test_adv_size,\n",
    "        engine=engine,\n",
    "        engine_settings={\n",
    "            **engine_settings,\n",
    "            \"threshold\": threshold,\n",
    "        },\n",
    "        modsec=modsec,\n",
    "        rule_ids=rule_ids,\n",
    "        paranoia_level=paranoia_level,\n",
    "    )\n",
    "    train_adv.to_csv(\n",
    "        f\"{processed_data_path}/train_adv_{train_adv_size}.csv\", index=False\n",
    "    )\n",
    "    test_adv.to_csv(f\"{processed_data_path}/test_adv_{test_adv_size}.csv\", index=False)\n",
    "    log(\"Adversarial train and test sets created\", True)\n",
    "else:\n",
    "    # load the train_adv and test_adv sets from disk\n",
    "    train_adv = pd.read_csv(f\"{processed_data_path}/train_adv_{train_adv_size}.csv\")\n",
    "    test_adv = pd.read_csv(f\"{processed_data_path}/test_adv_{test_adv_size}.csv\")\n",
    "    train_adv[\"vector\"] = train_adv[\"vector\"].apply(\n",
    "        lambda x: np.fromstring(x[1:-1], sep=\" \")\n",
    "    )\n",
    "    test_adv[\"vector\"] = test_adv[\"vector\"].apply(\n",
    "        lambda x: np.fromstring(x[1:-1], sep=\" \")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new model with train + train_adv\n",
    "\n",
    "wafamole_model_adv, threshold_adv = create_model(\n",
    "    train=pd.concat([train, train_adv]).sample(frac=1).reset_index(drop=True),\n",
    "    test=pd.concat([test, test_adv]).sample(frac=1).reset_index(drop=True),\n",
    "    model=model_adv,\n",
    "    desired_fpr=0.01,\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model (without adversarial training)\n",
    "test_evasion(\n",
    "    payload='SELECT SLEEP(5)#\";',\n",
    "    threshold=threshold,\n",
    "    model=wafamole_model,\n",
    "    engine=EvasionEngine(wafamole_model),\n",
    "    engine_eval_settings={\n",
    "        \"max_rounds\": 200,\n",
    "        \"round_size\": 10,\n",
    "        \"timeout\": 60,\n",
    "        \"threshold\": 0.0,\n",
    "    },\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model (with adversarial training)\n",
    "test_evasion(\n",
    "    payload='SELECT SLEEP(5)#\";',\n",
    "    threshold=threshold,\n",
    "    model=wafamole_model_adv,\n",
    "    engine=EvasionEngine(wafamole_model_adv),\n",
    "    engine_eval_settings={\n",
    "        \"max_rounds\": 200,\n",
    "        \"round_size\": 10,\n",
    "        \"timeout\": 60,\n",
    "        \"threshold\": 0.0,\n",
    "    },\n",
    "    modsec=modsec,\n",
    "    rule_ids=rule_ids,\n",
    "    paranoia_level=paranoia_level,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
